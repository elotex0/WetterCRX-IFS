name: Fetch ECMWF GRIB2 and Generate PNGs

on:
  workflow_dispatch:

jobs:
  fetch_and_generate:
    runs-on: ubuntu-latest
    outputs:
      run: ${{ steps.set_run_date.outputs.run }}

    steps:
      - name: Checkout Repo
        uses: actions/checkout@v3
        with:
          token: ${{ secrets.ECMWF_PAT }}

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'


      - name: Cache Python packages
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      
      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Set RUN and DATE
        id: set_run_date
        run: |
          HOUR=$(date -u +%H)
          case $HOUR in
            07|08|09|11|12|18) RUN=00 ;;
            19|20|21|22) RUN=12 ;;
          esac
          DATE=$(date -u +%Y%m%d)
          # set env variables
          echo "RUN=$RUN" >> $GITHUB_ENV
          echo "DATE=$DATE" >> $GITHUB_ENV
          # set step output for job output
          echo "run=$RUN" >> $GITHUB_OUTPUT

      - name: Download Grib2
        run: |
          python downloads/2t.py &
          python downloads/msl.py &
          python downloads/ptype.py &
          python downloads/gh.py &
          wait
          python downloads/tp_acc.py &
          python downloads/snow.py &
          python downloads/snowcm.py &
          wait
          
      - name: Upload GRIB2 as artifact
        uses: actions/upload-artifact@v4
        with:
          name: grib2
          path: data/

      - name: Delete GRIB2 files (local cleanup)
        run: rm -rf data/


  generate_pngs:
    runs-on: ubuntu-latest
    needs: fetch_and_generate
    strategy:
      matrix:
        variable: [t2m, ww, pmsl_eu, pmsl, geo_eu, ww_eu, t2m_eu, tp_acc, snow, snow1cm, snow2cm]
      max-parallel: 11
    steps:
      - name: Checkout Repo
        uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Download GRIB2 artifact
        uses: actions/download-artifact@v4
        with:
          name: grib2
          path: data/

      - name: Generate PNGs for ${{ matrix.variable }}
        run: |
          mkdir -p ifs/${{ matrix.variable }}
          input_dir="data/${{ matrix.variable }}"
          if [ "${{ matrix.variable }}" = "pmsl_eu" ]; then
            input_dir="data/pmsl"
          elif [ "${{ matrix.variable }}" = "geo_eu" ]; then
            input_dir="data/geo"
          elif [ "${{ matrix.variable }}" = "ww_eu" ]; then
            input_dir="data/ww"
          elif [ "${{ matrix.variable }}" = "t2m_eu" ]; then
            input_dir="data/t2m"
          fi
          python scripts/generate_pngs.py \
            "$input_dir" \
            ifs/${{ matrix.variable }} \
            ${{ matrix.variable }}


      - name: Upload PNGs artifact
        uses: actions/upload-artifact@v4
        with:
          name: ifs-${{ matrix.variable }}
          path: ifs/${{ matrix.variable }}

  deploy_to_r2:
    runs-on: ubuntu-latest
    needs: [fetch_and_generate, generate_pngs]
    steps:
      - name: Checkout Repo
        uses: actions/checkout@v3

      - name: Download all PNGs artifact
        uses: actions/download-artifact@v4
        with:
          pattern: ifs-*
          path: ifs_raw

      - name: Merge PNG folders into one structure
        run: |
          mkdir -p ifs/${{ needs.fetch_and_generate.outputs.run }}
          for d in ifs_raw/*; do
            if [ -d "$d" ]; then
              varname=$(basename "$d" | sed 's/^ifs-//')  # entfernt "ifs-" Prefix
              mkdir -p ifs/${{ needs.fetch_and_generate.outputs.run }}/"$varname"
              cp -r "$d"/* ifs/${{ needs.fetch_and_generate.outputs.run }}/"$varname"/ || true
            fi
          done

      - name: Generate Metadata
        run: |
          python scripts/generate_metadata.py ifs/${{ needs.fetch_and_generate.outputs.run }} ${{ needs.fetch_and_generate.outputs.run }} ${{ env.DATE }}

      - name: Clean old runs on R2 except current
        run: |
          for run_folder in $(aws s3 ls s3://${{ secrets.R2_BUCKET }}/ifs/ --endpoint-url https://${{ secrets.R2_ACCOUNT_ID }}.r2.cloudflarestorage.com | awk '{print $2}' | sed 's#/##'); do
            if [ "$run_folder" != "${{ needs.fetch_and_generate.outputs.run }}/" ]; then
              aws s3 rm s3://${{ secrets.R2_BUCKET }}/ifs/$run_folder --recursive --endpoint-url https://${{ secrets.R2_ACCOUNT_ID }}.r2.cloudflarestorage.com
            fi
          done
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}

      - name: Upload current run and metadata.json to R2
        run: |
          # Upload run folder
          aws s3 sync ./ifs/${{ needs.fetch_and_generate.outputs.run }}/ s3://${{ secrets.R2_BUCKET }}/ifs/${{ needs.fetch_and_generate.outputs.run }}/ \
            --endpoint-url https://${{ secrets.R2_ACCOUNT_ID }}.r2.cloudflarestorage.com

          # Upload metadata.json outside run folder
          aws s3 cp ./ifs/metadata.json s3://${{ secrets.R2_BUCKET }}/ifs/metadata.json \
            --endpoint-url https://${{ secrets.R2_ACCOUNT_ID }}.r2.cloudflarestorage.com
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
